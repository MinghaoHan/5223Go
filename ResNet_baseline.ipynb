{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinghaoHan/5223Go/blob/main/ResNet_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this file, we focus on the training and evaluation for the ResNet-50 with and without pretrained weights, the model performance without pretrain weights will be considered as a baseline.\n",
        "\n",
        "Before running this code with pretrained weights, please make sure you have downloaded the pretrained weights from https://download.pytorch.org/models/resnet50-11ad3fa6.pth"
      ],
      "metadata": {
        "id": "IKxkyZ9K1DhC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLZVHxQZncwm"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# switch to the path where the dataset is stored\n",
        "%cd /content/drive/MyDrive/CS4243Project/dataset/\n",
        "# copy the dataset (.zip) to the /content path\n",
        "!cp frames-TVT.zip /content\n",
        "# switch to content directory\n",
        "%cd /content\n",
        "# unzip dataset zip file\n",
        "!unzip frames-TVT.zip -d '/content/'"
      ],
      "metadata": {
        "id": "M4-ttAj584jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check\n",
        "def count_files_in_folder(folder_path):\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        file_count = len(files)\n",
        "        print(f\"{root} contains {file_count} files\")\n",
        "\n",
        "dir_path = '/content/frames-TVT/'\n",
        "count_files_in_folder(dir_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izo0kZqfQDTb",
        "outputId": "b2783fc8-0ccb-4699-a372-9d70e22790f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/frames-TVT/ contains 1 files\n",
            "/content/frames-TVT/train contains 1 files\n",
            "/content/frames-TVT/train/weap contains 1183 files\n",
            "/content/frames-TVT/train/norm contains 1648 files\n",
            "/content/frames-TVT/val contains 1 files\n",
            "/content/frames-TVT/val/weap contains 296 files\n",
            "/content/frames-TVT/val/norm contains 412 files\n",
            "/content/frames-TVT/test contains 1 files\n",
            "/content/frames-TVT/test/weap contains 779 files\n",
            "/content/frames-TVT/test/norm contains 1292 files\n",
            "/content/frames-TVT/train_all contains 1 files\n",
            "/content/frames-TVT/train_all/weap contains 1478 files\n",
            "/content/frames-TVT/train_all/norm contains 2059 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAczZTSKqkWM",
        "outputId": "0afd1fa8-59f3-4ffe-d9d2-bba67da444e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 16 07:09:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5TPJMooB67",
        "outputId": "a7f73bac-c821-4cd3-95cb-585bbbb99024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append('/content/drive/MyDrive/CS4243Project/')\n",
        "sys.path.append('/content/drive/MyDrive/CS4243Project/ResNet50/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kziUiSHrn8wM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "from model import resnet50\n",
        "\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4-CDU46YX0Bz",
        "outputId": "40d63667-57ba-457b-a681-36ffff51cacb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda:0 device.\n",
            "Using 2 dataloader workers every process\n",
            "using 3537 images for training, 2071 images for validation.\n",
            "train epoch[1/20] loss:0.602: 100%|██████████| 111/111 [03:32<00:00,  1.91s/it]\n",
            "valid epoch[1/20]: 100%|██████████| 65/65 [01:56<00:00,  1.80s/it]\n",
            "[epoch 1] train_loss: 0.647  val_accuracy: 0.730  val_f1_score: 0.550\n",
            "[[1170  122]\n",
            " [ 437  342]]\n",
            "train epoch[2/20] loss:0.553: 100%|██████████| 111/111 [03:22<00:00,  1.83s/it]\n",
            "valid epoch[2/20]: 100%|██████████| 65/65 [01:58<00:00,  1.82s/it]\n",
            "[epoch 2] train_loss: 0.571  val_accuracy: 0.748  val_f1_score: 0.585\n",
            "[[1181  111]\n",
            " [ 411  368]]\n",
            "train epoch[3/20] loss:0.480: 100%|██████████| 111/111 [03:30<00:00,  1.90s/it]\n",
            "valid epoch[3/20]: 100%|██████████| 65/65 [01:59<00:00,  1.84s/it]\n",
            "[epoch 3] train_loss: 0.523  val_accuracy: 0.750  val_f1_score: 0.598\n",
            "[[1170  122]\n",
            " [ 395  384]]\n",
            "train epoch[4/20] loss:0.525: 100%|██████████| 111/111 [03:30<00:00,  1.90s/it]\n",
            "valid epoch[4/20]: 100%|██████████| 65/65 [01:58<00:00,  1.82s/it]\n",
            "[epoch 4] train_loss: 0.488  val_accuracy: 0.755  val_f1_score: 0.609\n",
            "[[1167  125]\n",
            " [ 383  396]]\n",
            "train epoch[5/20] loss:0.546: 100%|██████████| 111/111 [03:29<00:00,  1.89s/it]\n",
            "valid epoch[5/20]: 100%|██████████| 65/65 [02:02<00:00,  1.88s/it]\n",
            "[epoch 5] train_loss: 0.457  val_accuracy: 0.754  val_f1_score: 0.619\n",
            "[[1148  144]\n",
            " [ 365  414]]\n",
            "train epoch[6/20] loss:0.554: 100%|██████████| 111/111 [03:32<00:00,  1.92s/it]\n",
            "valid epoch[6/20]: 100%|██████████| 65/65 [02:02<00:00,  1.88s/it]\n",
            "[epoch 6] train_loss: 0.431  val_accuracy: 0.763  val_f1_score: 0.620\n",
            "[[1181  111]\n",
            " [ 379  400]]\n",
            "train epoch[7/20] loss:0.439: 100%|██████████| 111/111 [03:31<00:00,  1.90s/it]\n",
            "valid epoch[7/20]: 100%|██████████| 65/65 [01:58<00:00,  1.83s/it]\n",
            "[epoch 7] train_loss: 0.412  val_accuracy: 0.762  val_f1_score: 0.632\n",
            "[[1156  136]\n",
            " [ 356  423]]\n",
            "train epoch[8/20] loss:0.363: 100%|██████████| 111/111 [03:28<00:00,  1.88s/it]\n",
            "valid epoch[8/20]: 100%|██████████| 65/65 [01:56<00:00,  1.80s/it]\n",
            "[epoch 8] train_loss: 0.391  val_accuracy: 0.760  val_f1_score: 0.622\n",
            "[[1165  127]\n",
            " [ 370  409]]\n",
            "train epoch[9/20] loss:0.354: 100%|██████████| 111/111 [03:26<00:00,  1.86s/it]\n",
            "valid epoch[9/20]: 100%|██████████| 65/65 [02:04<00:00,  1.91s/it]\n",
            "[epoch 9] train_loss: 0.382  val_accuracy: 0.763  val_f1_score: 0.626\n",
            "[[1171  121]\n",
            " [ 369  410]]\n",
            "train epoch[10/20] loss:0.446: 100%|██████████| 111/111 [03:33<00:00,  1.92s/it]\n",
            "valid epoch[10/20]: 100%|██████████| 65/65 [02:02<00:00,  1.88s/it]\n",
            "[epoch 10] train_loss: 0.360  val_accuracy: 0.764  val_f1_score: 0.639\n",
            "[[1152  140]\n",
            " [ 348  431]]\n",
            "train epoch[11/20] loss:0.305: 100%|██████████| 111/111 [03:33<00:00,  1.92s/it]\n",
            "valid epoch[11/20]: 100%|██████████| 65/65 [02:03<00:00,  1.89s/it]\n",
            "[epoch 11] train_loss: 0.356  val_accuracy: 0.763  val_f1_score: 0.620\n",
            "[[1179  113]\n",
            " [ 378  401]]\n",
            "train epoch[12/20] loss:0.349: 100%|██████████| 111/111 [03:30<00:00,  1.90s/it]\n",
            "valid epoch[12/20]: 100%|██████████| 65/65 [02:00<00:00,  1.85s/it]\n",
            "[epoch 12] train_loss: 0.351  val_accuracy: 0.761  val_f1_score: 0.633\n",
            "[[1151  141]\n",
            " [ 353  426]]\n",
            "train epoch[13/20] loss:0.367: 100%|██████████| 111/111 [03:28<00:00,  1.88s/it]\n",
            "valid epoch[13/20]: 100%|██████████| 65/65 [01:59<00:00,  1.84s/it]\n",
            "[epoch 13] train_loss: 0.340  val_accuracy: 0.757  val_f1_score: 0.639\n",
            "[[1123  169]\n",
            " [ 334  445]]\n",
            "train epoch[14/20] loss:0.252: 100%|██████████| 111/111 [03:28<00:00,  1.88s/it]\n",
            "valid epoch[14/20]: 100%|██████████| 65/65 [01:59<00:00,  1.85s/it]\n",
            "[epoch 14] train_loss: 0.324  val_accuracy: 0.762  val_f1_score: 0.637\n",
            "[[1148  144]\n",
            " [ 348  431]]\n",
            "train epoch[15/20] loss:0.370: 100%|██████████| 111/111 [03:27<00:00,  1.87s/it]\n",
            "valid epoch[15/20]: 100%|██████████| 65/65 [01:58<00:00,  1.83s/it]\n",
            "[epoch 15] train_loss: 0.319  val_accuracy: 0.758  val_f1_score: 0.637\n",
            "[[1129  163]\n",
            " [ 339  440]]\n",
            "train epoch[16/20] loss:0.402:   9%|▉         | 10/111 [00:22<03:50,  2.28s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c7bc734e5e35>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-36de70b2a111>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mtrain_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIn0RqMMkDE_"
      },
      "outputs": [],
      "source": [
        "def evaluate_on_test():\n",
        "\n",
        "    batch_size = 32\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(\"using {} device.\".format(device))\n",
        "\n",
        "    results_file = \"/content/drive/MyDrive/CS4243Project/ResNet50/save_weights/test_results{}.txt\".format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
        "\n",
        "    data_transform = {\n",
        "        \"test\": transforms.Compose([transforms.Resize(256),\n",
        "                                   transforms.CenterCrop(224),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
        "\n",
        "    image_path = \"/content/frames-TVT/\"\n",
        "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
        "    test_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"test\"), transform=data_transform[\"test\"])\n",
        "    test_num = len(test_dataset)\n",
        "\n",
        "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
        "    print('Using {} dataloader workers every process'.format(nw))\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=nw)\n",
        "    print(\"using {} images for testing.\".format(test_num))\n",
        "\n",
        "    net = resnet50()\n",
        "    # change fc layer structure\n",
        "    in_channel = net.fc.in_features\n",
        "    net.fc = nn.Linear(in_channel, 2) # number of classes\n",
        "\n",
        "    # load best weights\n",
        "    model_weight_path = \"/content/drive/MyDrive/CS4243Project/ResNet50/save_weights/reset50-9.pth\"\n",
        "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
        "    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "    # define loss function\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    all_test_real = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    # test\n",
        "    net.eval()\n",
        "    acc = 0.0  # accumulate accurate number / epoch\n",
        "    test_loss = 0.0 # loss\n",
        "    with torch.no_grad():\n",
        "        test_bar = tqdm(test_loader, file=sys.stdout)\n",
        "        for test_data in test_bar:\n",
        "            test_images, test_labels = test_data\n",
        "            outputs = net(test_images.to(device))\n",
        "            loss = loss_function(outputs, test_labels.to(device)) # loss\n",
        "            test_loss += loss.item() # loss\n",
        "            predict_y = torch.max(outputs, dim=1)[1]\n",
        "            all_test_pred.extend(predict_y.cpu().tolist())\n",
        "            all_test_real.extend(test_labels.tolist())\n",
        "            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
        "\n",
        "            test_bar.desc = \"Test epoch[{}/{}]\".format(1,1)\n",
        "\n",
        "    test_accurate = acc / test_num\n",
        "    conf_mat = confusion_matrix(all_test_real, all_test_pred)\n",
        "    test_f1 = f1_score(all_test_real, all_test_pred)\n",
        "    report = classification_report(all_test_real, all_test_pred)\n",
        "\n",
        "    #print('Checking accuracy:', val_accurate, accuracy_score(all_valid_real, all_valid_pred))\n",
        "    print('[Tesing]  test_loss: %.3f  test_accuracy: %.3f  test_f1_score: %.3f' %\n",
        "          (test_loss, test_accurate, test_f1))\n",
        "    print(conf_mat)\n",
        "    print(report)\n",
        "\n",
        "    # write into txt\n",
        "    # with open(results_file, \"a\") as f:\n",
        "    #     txt = \"Epoch: {}, valid_acc: {}, valid_f1: {}.\".format(epoch, val_accurate, valid_f1)\n",
        "    #     txt = \"train_loss: {}\".format('  '.join([f\"{i:.4f}\" for i in train_loss_epoch]))\n",
        "    #     txt = \"valid_loss: {}\".format('  '.join([f\"{i:.4f}\" for i in valid_loss_epoch]))\n",
        "    #     f.write(txt + \"\\n\")\n",
        "\n",
        "    print('Finished Testing')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wKqoPTRn8zJ"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    batch_size = 32\n",
        "    epochs = 20\n",
        "    lr = 1e-4\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(\"using {} device.\".format(device))\n",
        "\n",
        "    results_file = \"/content/drive/MyDrive/CS4243Project/ResNet50/save_weights/results{}.txt\".format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
        "\n",
        "    data_transform = {\n",
        "        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "        \"val\": transforms.Compose([transforms.Resize(256),\n",
        "                                   transforms.CenterCrop(224),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
        "\n",
        "    image_path = \"/content/frames-TVT/\"\n",
        "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
        "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train_all\"), transform=data_transform[\"train\"])\n",
        "    train_num = len(train_dataset)\n",
        "\n",
        "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])\n",
        "    print('Using {} dataloader workers every process'.format(nw))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=nw)\n",
        "    # val set\n",
        "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"test\"), transform=data_transform[\"val\"])\n",
        "    val_num = len(validate_dataset)\n",
        "    validate_loader = torch.utils.data.DataLoader(validate_dataset, batch_size=batch_size, shuffle=False, num_workers=nw)\n",
        "\n",
        "    print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
        "\n",
        "    net = resnet50()\n",
        "\n",
        "    model_weight_path = \"/content/drive/MyDrive/CS4243Project/resnet50-pretrained.pth\"\n",
        "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
        "    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
        "\n",
        "    # freeze feature extractor layer weights\n",
        "    for param in net.parameters():\n",
        "        param.requires_grad = False # false: freeze\n",
        "\n",
        "    # # change fc layer structure\n",
        "    in_channel = net.fc.in_features\n",
        "    net.fc = nn.Linear(in_channel, 2) # number of classes\n",
        "    net.to(device)\n",
        "\n",
        "    # loss function\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    # optimizer\n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "    optimizer = optim.Adam(params, lr=lr)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # loss\n",
        "    train_loss_epoch = []\n",
        "    valid_loss_epoch = []\n",
        "\n",
        "    train_steps = len(train_loader)\n",
        "    for epoch in range(epochs):\n",
        "        all_valid_real = []\n",
        "        all_valid_pred = []\n",
        "        # train\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            logits = net(images.to(device))\n",
        "            loss = loss_function(logits, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,epochs,loss)\n",
        "        train_loss_epoch.append(running_loss) # loss\n",
        "\n",
        "        # eval\n",
        "        net.eval()\n",
        "        acc = 0.0  # accumulate accurate number / epoch\n",
        "        val_loss = 0.0 # loss\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                outputs = net(val_images.to(device))\n",
        "                loss = loss_function(outputs, val_labels.to(device)) # loss\n",
        "                val_loss += loss.item() # loss\n",
        "                predict_y = torch.max(outputs, dim=1)[1]\n",
        "                all_valid_pred.extend(predict_y.cpu().tolist())\n",
        "                all_valid_real.extend(val_labels.tolist())\n",
        "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
        "\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,epochs)\n",
        "\n",
        "        valid_loss_epoch.append(val_loss) # loss\n",
        "        val_accurate = acc / val_num\n",
        "        conf_mat = confusion_matrix(all_valid_real, all_valid_pred)\n",
        "        valid_f1 = f1_score(all_valid_real, all_valid_pred)\n",
        "\n",
        "        #print('Checking accuracy:', val_accurate, accuracy_score(all_valid_real, all_valid_pred))\n",
        "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f  val_f1_score: %.3f' %\n",
        "              (epoch + 1, running_loss / train_steps, val_accurate, valid_f1))\n",
        "        print(conf_mat)\n",
        "\n",
        "        # write into txt\n",
        "        with open(results_file, \"a\") as f:\n",
        "            # validation metrics\n",
        "            txt = \"Epoch: {}, valid_acc: {}, valid_f1: {}.\".format(epoch, val_accurate, valid_f1)\n",
        "            f.write(txt + \"\\n\")\n",
        "            txt = \"train_loss: {}\".format('  '.join([f\"{i:.4f}\" for i in train_loss_epoch]))\n",
        "            f.write(txt + \"\\n\")\n",
        "            txt = \"valid_loss: {}\".format('  '.join([f\"{i:.4f}\" for i in valid_loss_epoch]))\n",
        "            f.write(txt + \"\\n\")\n",
        "\n",
        "\n",
        "        # if val_accurate > best_acc:\n",
        "        #     best_acc = val_accurate\n",
        "        torch.save(net.state_dict(), \"/content/drive/MyDrive/CS4243Project/ResNet50/save_weights/reset50-{}.pth\".format(epoch))\n",
        "\n",
        "    # write into txt\n",
        "    with open(results_file, \"a\") as f:\n",
        "        # train loss & valid loss\n",
        "        txt = \"train_loss: {}\".format('  '.join([f\"{i:.4f}\" for i in train_loss_epoch]))\n",
        "        f.write(txt + \"\\n\")\n",
        "        txt = \"valid_loss: {}\".format('  '.join([f\"{i:.4f}\" for i in valid_loss_epoch]))\n",
        "        f.write(txt + \"\\n\")\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    plt.plot([*range(epochs)], train_loss_epoch, label='Train Loss')\n",
        "    plt.plot([*range(epochs)], valid_loss_epoch, label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Train Loss vs. Validation Loss')\n",
        "    plt.savefig('/content/drive/MyDrive/CS4243Project/ResNet50/Loss.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_on_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlvW4cvFJiWa",
        "outputId": "5d52efa0-0e19-4bb6-9a70-485bb67816c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda:0 device.\n",
            "Using 2 dataloader workers every process\n",
            "using 2071 images for testing.\n",
            "Test epoch[1/1]: 100%|██████████| 65/65 [02:00<00:00,  1.85s/it]\n",
            "[Tesing]  test_loss: 31.649  test_accuracy: 0.764  test_f1_score: 0.639\n",
            "[[1152  140]\n",
            " [ 348  431]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.89      0.83      1292\n",
            "           1       0.75      0.55      0.64       779\n",
            "\n",
            "    accuracy                           0.76      2071\n",
            "   macro avg       0.76      0.72      0.73      2071\n",
            "weighted avg       0.76      0.76      0.75      2071\n",
            "\n",
            "Finished Testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhy2zlF1JkLQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}